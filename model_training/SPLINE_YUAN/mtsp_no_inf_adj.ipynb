{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddcf8ed5",
   "metadata": {},
   "source": [
    "It was reported by the MARS team that py-earth is outdated. The MARS team resorted to suing spline then linear regression pipeline. I will adopt this decision, I might also look into if I could use rpy2 to use mars from r instead (if I have time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cf44fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3690ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../../\")\n",
    "from proj_mod import drop_extreme\n",
    "from proj_mod import data_shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a75d9b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.read_csv(\"../../data/processed/all_data_collection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0372a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_extended = all_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88dadfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_cols_shift=['tech_index_daily_pro_change', 'cop_daily_pro_change',\n",
    "       'gold_daily_pro_change', 'silv_daily_pro_change',\n",
    "       'pal_daily_pro_change', 'plat_daily_pro_change',\n",
    "       'crude_oil_daily_pro_change']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099dbd5",
   "metadata": {},
   "source": [
    "To my knowledge, people normally use degree 3 with spline polynomial degree. In experience with EBM, it seems that 10 shifting provides a better \"slope\" to the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d9e4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import SplineTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3dccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_extended = all_data.copy(deep=True)\n",
    "for int_extend in range(11): \n",
    "    if int_extend != 0: \n",
    "        for col in lst_cols_shift: \n",
    "            all_data_extended=data_shifting.shifter(df_in=all_data_extended,str_col=col,int_shift=int_extend)\n",
    "all_data_extended_train=all_data_extended[all_data_extended[\"Date\"]<\"2024-01-01\"].dropna()\n",
    "all_data_extended_train_de=drop_extreme.drop_by_sort(df_in=all_data_extended_train,fl_low=0.001,fl_high=0.999)\n",
    "all_data_extended_test=all_data_extended[all_data_extended[\"Date\"]>=\"2024-01-01\"].dropna()\n",
    "all_data_extended_test_de=drop_extreme.drop_by_sort(df_in=all_data_extended_test,fl_low=0.01,fl_high=0.99)\n",
    "X_train=all_data_extended_train.iloc[:,2:]\n",
    "y_train=all_data_extended_train.iloc[:,1]\n",
    "X_de_train=all_data_extended_train_de.iloc[:,2:]\n",
    "y_de_train=all_data_extended_train_de.iloc[:,1]\n",
    "X_test=all_data_extended_test.iloc[:,2:]\n",
    "y_test=all_data_extended_test.iloc[:,1]\n",
    "X_de_test=all_data_extended_test_de.iloc[:,2:]\n",
    "y_de_test=all_data_extended_test_de.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6741105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sp_pipe(int_knots,int_deg): \n",
    "    return Pipeline([\n",
    "    (\"std\", StandardScaler()),  \n",
    "    (\"spline\", SplineTransformer(n_knots=int_knots, degree=int_deg)),\n",
    "    (\"regressor\", LinearRegression())          \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d2e7a",
   "metadata": {},
   "source": [
    "\n",
    "At first, I would like to do cross validation on knots only, or degree only, but it seems that, after some testing, only knots=2 and deg=1 gives the best outcome, this is almost the same as simply running a linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e0fca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse trained on 2 knots and WITHOUT deleting extreme values is 2.242200672138371 with k fold.\n",
      "mse trained on 2 knots and WITH deleting extreme values is 2.27261045873911 with k fold.\n",
      "\n",
      "Finished training and testing for 2 knots.\n",
      "mse trained on 3 knots and WITHOUT deleting extreme values is 3.271700838033316 with k fold.\n",
      "mse trained on 3 knots and WITH deleting extreme values is 3.3637519156386455 with k fold.\n",
      "\n",
      "Finished training and testing for 3 knots.\n",
      "mse trained on 4 knots and WITHOUT deleting extreme values is 6.341562078653881 with k fold.\n",
      "mse trained on 4 knots and WITH deleting extreme values is 5.644421991651738 with k fold.\n",
      "\n",
      "Finished training and testing for 4 knots.\n",
      "mse trained on 5 knots and WITHOUT deleting extreme values is 130.06541873993166 with k fold.\n",
      "mse trained on 5 knots and WITH deleting extreme values is 128.40649659371905 with k fold.\n",
      "\n",
      "Finished training and testing for 5 knots.\n"
     ]
    }
   ],
   "source": [
    "arr_mse_kfold_collection=[] #Each row is for one int_extend. Then for each row index zero is for the training with extreme values, and index one is for the training without extreme values. \n",
    "arr_mse_kfold_de_collection=[] #Each row is for one int_extend. Then for each row index zero is for the training with extreme values, and index one is for the training without extreme values. \n",
    "for int_i in range(2,6): \n",
    "    # if int_extend != 0: \n",
    "    #     for col in lst_cols_shift: \n",
    "    #         all_data_extended=data_shifting.shifter(df_in=all_data_extended,str_col=col,int_shift=int_extend)\n",
    "    all_data_extended_train=all_data_extended[all_data_extended[\"Date\"]<\"2024-01-01\"].dropna()\n",
    "    # all_data_extended_de=drop_extreme.drop_by_sort(df_in=all_data_extended.dropna(),fl_low=0.001,fl_high=0.999)\n",
    "    # all_data_extended_train_de=drop_extreme.drop_by_sort(df_in=all_data_extended_train,fl_low=0.001,fl_high=0.999)\n",
    "    # all_data_extended_test=all_data_extended[all_data_extended[\"Date\"]>=\"2024-01-01\"].dropna()\n",
    "    X_train=all_data_extended_train.iloc[:,2:]\n",
    "    y_train=all_data_extended_train.iloc[:,1]\n",
    "    # X_de_train=all_data_extended_train_de.iloc[:,2:]\n",
    "    # y_de_train=all_data_extended_train_de.iloc[:,1]\n",
    "    # X_test=all_data_extended_test.iloc[:,2:]\n",
    "    # y_test=all_data_extended_test.iloc[:,1]\n",
    "    # ebm_pipe=Pipeline([(\"std\",StandardScaler()),(\"ebm\",ExplainableBoostingRegressor())])\n",
    "    time_kfold=TimeSeriesSplit(n_splits=5)\n",
    "    fold_mse=[]\n",
    "    fold_mse_de=[]\n",
    "    #First for without deleting extreme values. \n",
    "    for index_train, index_test in time_kfold.split(X_train): \n",
    "        X_tt=X_train.iloc[index_train]\n",
    "        y_tt=y_train.iloc[index_train]\n",
    "        X_ho=X_train.iloc[index_test]\n",
    "        y_ho=y_train.iloc[index_test]\n",
    "        all_data_ho_de=drop_extreme.drop_by_sort(df_in=all_data_extended_train.iloc[index_test], fl_low=0.01, fl_high=0.99)\n",
    "        X_ho_de=all_data_ho_de.iloc[:,2:]\n",
    "        y_ho_de=all_data_ho_de.iloc[:,1]\n",
    "        sp_pipe=create_sp_pipe(int_knots=int_i,int_deg=1)\n",
    "        sp_pipe.fit(X=X_tt,y=y_tt)\n",
    "        # ebm_pipe.fit(X=X_tt,y=y_tt)\n",
    "        pred=sp_pipe.predict(X=X_ho)\n",
    "        # pred=ebm_pipe.predict(X=X_ho)\n",
    "        error=mean_squared_error(y_pred=pred,y_true=y_ho)\n",
    "        fold_mse.append(error)\n",
    "        pred_de=sp_pipe.predict(X=X_ho_de)\n",
    "        # pred_de=ebm_pipe.predict(X=X_ho_de)\n",
    "        error_de=mean_squared_error(y_pred=pred_de,y_true=y_ho_de)\n",
    "        fold_mse_de.append(error_de)\n",
    "    mean_error=np.mean(fold_mse)\n",
    "    arr_mse_kfold_collection.append([])\n",
    "    arr_mse_kfold_collection[-1].append(mean_error)\n",
    "    mean_error_de=np.mean(fold_mse_de)\n",
    "    arr_mse_kfold_de_collection.append([])\n",
    "    arr_mse_kfold_de_collection[-1].append(mean_error_de)\n",
    "    print(\"mse trained on \"+str(int_i)+\" knots and WITHOUT deleting extreme values is \"+str(mean_error)+\" with k fold.\")\n",
    "    fold_mse=[]\n",
    "    fold_mse_de=[]\n",
    "    #Then the one with deleting extreme values. \n",
    "    for index_train, index_test in time_kfold.split(X_train): \n",
    "        all_data_tt=drop_extreme.drop_by_sort(df_in=all_data_extended_train.iloc[index_train], fl_low=0.001, fl_high=0.999)  #all_data_extended_train.iloc[index_train]\n",
    "        all_data_ho=drop_extreme.drop_by_sort(df_in=all_data_extended_train.iloc[index_test], fl_low=0.01, fl_high=0.99) #all_data_extended_train.iloc[index_test]\n",
    "        X_tt=all_data_tt.iloc[:,2:] #drop_extreme.drop_by_sort(df_in=X_train.iloc[index_train], fl_low=0.01, fl_high=0.99)     #X_de_train.iloc[index_train]\n",
    "        y_tt=all_data_tt.iloc[:,1] #drop_extreme.drop_by_sort(df_in=y_train.iloc[index_train], fl_low=0.01, fl_high=0.99) \n",
    "        X_ho_de=all_data_ho.iloc[:,2:] #drop_extreme.drop_by_sort(df_in=X_train.iloc[index_test], fl_low=0.01, fl_high=0.99) #X_train.iloc[index_test]\n",
    "        y_ho_de=all_data_ho.iloc[:,1] #drop_extreme.drop_by_sort(df_in=y_train.iloc[index_test], fl_low=0.01, fl_high=0.99) #y_train.iloc[index_test]\n",
    "        X_ho=X_train.iloc[index_test]\n",
    "        y_ho=y_train.iloc[index_test]\n",
    "        sp_pipe=create_sp_pipe(int_knots=int_i,int_deg=1)\n",
    "        sp_pipe.fit(X=X_tt,y=y_tt)\n",
    "        # ebm_pipe.fit(X=X_tt,y=y_tt)\n",
    "        pred=sp_pipe.predict(X=X_ho)\n",
    "        # pred=ebm_pipe.predict(X=X_ho)\n",
    "        error=mean_squared_error(y_pred=pred,y_true=y_ho)\n",
    "        fold_mse.append(error)\n",
    "        pred_de=sp_pipe.predict(X=X_ho_de)\n",
    "        # pred_de=ebm_pipe.predict(X=X_ho_de)\n",
    "        error_de=mean_squared_error(y_pred=pred_de,y_true=y_ho_de)\n",
    "        fold_mse_de.append(error_de)\n",
    "    mean_error=np.mean(fold_mse)\n",
    "    arr_mse_kfold_collection[-1].append(mean_error)\n",
    "    mean_error_de=np.mean(fold_mse_de)\n",
    "    arr_mse_kfold_de_collection[-1].append(mean_error_de)\n",
    "    print(\"mse trained on \"+str(int_i)+\" knots and WITH deleting extreme values is \"+str(mean_error)+\" with k fold.\")\n",
    "    print(\"\\n\"+\"Finished training and testing for \"+str(int_i)+\" knots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcfc3db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse trained on 1 degree and WITHOUT deleting extreme values is 2.242200672138371 with k fold.\n",
      "mse trained on 1 degree and WITH deleting extreme values is 2.27261045873911 with k fold.\n",
      "\n",
      "Finished training and testing for 1 degree.\n",
      "mse trained on 2 degree and WITHOUT deleting extreme values is 3.4615019536372067 with k fold.\n",
      "mse trained on 2 degree and WITH deleting extreme values is 3.4985422253026046 with k fold.\n",
      "\n",
      "Finished training and testing for 2 degree.\n",
      "mse trained on 3 degree and WITHOUT deleting extreme values is 8.137809352118662 with k fold.\n",
      "mse trained on 3 degree and WITH deleting extreme values is 8.539543410164157 with k fold.\n",
      "\n",
      "Finished training and testing for 3 degree.\n",
      "mse trained on 4 degree and WITHOUT deleting extreme values is 180.0526143199764 with k fold.\n",
      "mse trained on 4 degree and WITH deleting extreme values is 180.06825253352437 with k fold.\n",
      "\n",
      "Finished training and testing for 4 degree.\n",
      "mse trained on 5 degree and WITHOUT deleting extreme values is 56900.92842817801 with k fold.\n",
      "mse trained on 5 degree and WITH deleting extreme values is 22917.37048124201 with k fold.\n",
      "\n",
      "Finished training and testing for 5 degree.\n"
     ]
    }
   ],
   "source": [
    "arr_mse_kfold_collection=[] #Each row is for one int_extend. Then for each row index zero is for the training with extreme values, and index one is for the training without extreme values. \n",
    "arr_mse_kfold_de_collection=[] #Each row is for one int_extend. Then for each row index zero is for the training with extreme values, and index one is for the training without extreme values. \n",
    "for int_i in range(1,6): \n",
    "    # if int_extend != 0: \n",
    "    #     for col in lst_cols_shift: \n",
    "    #         all_data_extended=data_shifting.shifter(df_in=all_data_extended,str_col=col,int_shift=int_extend)\n",
    "    all_data_extended_train=all_data_extended[all_data_extended[\"Date\"]<\"2024-01-01\"].dropna()\n",
    "    # all_data_extended_de=drop_extreme.drop_by_sort(df_in=all_data_extended.dropna(),fl_low=0.001,fl_high=0.999)\n",
    "    # all_data_extended_train_de=drop_extreme.drop_by_sort(df_in=all_data_extended_train,fl_low=0.001,fl_high=0.999)\n",
    "    # all_data_extended_test=all_data_extended[all_data_extended[\"Date\"]>=\"2024-01-01\"].dropna()\n",
    "    X_train=all_data_extended_train.iloc[:,2:]\n",
    "    y_train=all_data_extended_train.iloc[:,1]\n",
    "    # X_de_train=all_data_extended_train_de.iloc[:,2:]\n",
    "    # y_de_train=all_data_extended_train_de.iloc[:,1]\n",
    "    # X_test=all_data_extended_test.iloc[:,2:]\n",
    "    # y_test=all_data_extended_test.iloc[:,1]\n",
    "    # ebm_pipe=Pipeline([(\"std\",StandardScaler()),(\"ebm\",ExplainableBoostingRegressor())])\n",
    "    time_kfold=TimeSeriesSplit(n_splits=5)\n",
    "    fold_mse=[]\n",
    "    fold_mse_de=[]\n",
    "    #First for without deleting extreme values. \n",
    "    for index_train, index_test in time_kfold.split(X_train): \n",
    "        X_tt=X_train.iloc[index_train]\n",
    "        y_tt=y_train.iloc[index_train]\n",
    "        X_ho=X_train.iloc[index_test]\n",
    "        y_ho=y_train.iloc[index_test]\n",
    "        all_data_ho_de=drop_extreme.drop_by_sort(df_in=all_data_extended_train.iloc[index_test], fl_low=0.01, fl_high=0.99)\n",
    "        X_ho_de=all_data_ho_de.iloc[:,2:]\n",
    "        y_ho_de=all_data_ho_de.iloc[:,1]\n",
    "        sp_pipe=create_sp_pipe(int_knots=2,int_deg=int_i)\n",
    "        sp_pipe.fit(X=X_tt,y=y_tt)\n",
    "        # ebm_pipe.fit(X=X_tt,y=y_tt)\n",
    "        pred=sp_pipe.predict(X=X_ho)\n",
    "        # pred=ebm_pipe.predict(X=X_ho)\n",
    "        error=mean_squared_error(y_pred=pred,y_true=y_ho)\n",
    "        fold_mse.append(error)\n",
    "        pred_de=sp_pipe.predict(X=X_ho_de)\n",
    "        # pred_de=ebm_pipe.predict(X=X_ho_de)\n",
    "        error_de=mean_squared_error(y_pred=pred_de,y_true=y_ho_de)\n",
    "        fold_mse_de.append(error_de)\n",
    "    mean_error=np.mean(fold_mse)\n",
    "    arr_mse_kfold_collection.append([])\n",
    "    arr_mse_kfold_collection[-1].append(mean_error)\n",
    "    mean_error_de=np.mean(fold_mse_de)\n",
    "    arr_mse_kfold_de_collection.append([])\n",
    "    arr_mse_kfold_de_collection[-1].append(mean_error_de)\n",
    "    print(\"mse trained on \"+str(int_i)+\" degree and WITHOUT deleting extreme values is \"+str(mean_error)+\" with k fold.\")\n",
    "    fold_mse=[]\n",
    "    fold_mse_de=[]\n",
    "    #Then the one with deleting extreme values. \n",
    "    for index_train, index_test in time_kfold.split(X_train): \n",
    "        all_data_tt=drop_extreme.drop_by_sort(df_in=all_data_extended_train.iloc[index_train], fl_low=0.001, fl_high=0.999)  #all_data_extended_train.iloc[index_train]\n",
    "        all_data_ho=drop_extreme.drop_by_sort(df_in=all_data_extended_train.iloc[index_test], fl_low=0.01, fl_high=0.99) #all_data_extended_train.iloc[index_test]\n",
    "        X_tt=all_data_tt.iloc[:,2:] #drop_extreme.drop_by_sort(df_in=X_train.iloc[index_train], fl_low=0.01, fl_high=0.99)     #X_de_train.iloc[index_train]\n",
    "        y_tt=all_data_tt.iloc[:,1] #drop_extreme.drop_by_sort(df_in=y_train.iloc[index_train], fl_low=0.01, fl_high=0.99) \n",
    "        X_ho_de=all_data_ho.iloc[:,2:] #drop_extreme.drop_by_sort(df_in=X_train.iloc[index_test], fl_low=0.01, fl_high=0.99) #X_train.iloc[index_test]\n",
    "        y_ho_de=all_data_ho.iloc[:,1] #drop_extreme.drop_by_sort(df_in=y_train.iloc[index_test], fl_low=0.01, fl_high=0.99) #y_train.iloc[index_test]\n",
    "        X_ho=X_train.iloc[index_test]\n",
    "        y_ho=y_train.iloc[index_test]\n",
    "        sp_pipe=create_sp_pipe(int_knots=2,int_deg=int_i)\n",
    "        sp_pipe.fit(X=X_tt,y=y_tt)\n",
    "        # ebm_pipe.fit(X=X_tt,y=y_tt)\n",
    "        pred=sp_pipe.predict(X=X_ho)\n",
    "        # pred=ebm_pipe.predict(X=X_ho)\n",
    "        error=mean_squared_error(y_pred=pred,y_true=y_ho)\n",
    "        fold_mse.append(error)\n",
    "        pred_de=sp_pipe.predict(X=X_ho_de)\n",
    "        # pred_de=ebm_pipe.predict(X=X_ho_de)\n",
    "        error_de=mean_squared_error(y_pred=pred_de,y_true=y_ho_de)\n",
    "        fold_mse_de.append(error_de)\n",
    "    mean_error=np.mean(fold_mse)\n",
    "    arr_mse_kfold_collection[-1].append(mean_error)\n",
    "    mean_error_de=np.mean(fold_mse_de)\n",
    "    arr_mse_kfold_de_collection[-1].append(mean_error_de)\n",
    "    print(\"mse trained on \"+str(int_i)+\" degree and WITH deleting extreme values is \"+str(mean_error)+\" with k fold.\")\n",
    "    print(\"\\n\"+\"Finished training and testing for \"+str(int_i)+\" degree.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398e551",
   "metadata": {},
   "source": [
    "This should be the reason that why the MARS team only looked at knots=2, degree=1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55980714",
   "metadata": {},
   "source": [
    "If I want anything more interesting, I should go look at how to use mars with r. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_bc_3_12_8_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
