{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ppi_files(filepaths):\n",
    "    \"\"\"\n",
    "    Reads multiple text files that each contain columns like:\n",
    "        series id | year | period | value | footnotes\n",
    "    and combines them into a single DataFrame covering 2003â€“2025.\n",
    "    \n",
    "    Steps:\n",
    "      1) Remove table border lines (lines starting with '+').\n",
    "      2) Parse the first non-removed line as the header.\n",
    "      3) Convert 'year' and 'value' to numeric; extract 'month' from 'period'.\n",
    "      4) Rename 'value' to 'ppi'.\n",
    "      5) Sort by (year, month) across *all* combined data.\n",
    "      6) Compute month-over-month proportional change (ppi_pro_change) across the entire timespan.\n",
    "      7) Expand monthly rows into daily rows.\n",
    "      8) Extract the NACIS code from the first file's name (or verify all have same NACIS).\n",
    "      9) Save the final daily DataFrame to 'data/processed/PPI{nacis}(03-25).csv'.\n",
    "      \n",
    "    Returns:\n",
    "      The combined daily DataFrame (covering 03-25).\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    all_dfs = []\n",
    "    \n",
    "    for filepath in filepaths:\n",
    "        # Read and parse each file individually\n",
    "        \n",
    "        with open(filepath, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Remove lines that start with '+'\n",
    "        data_lines = [line for line in lines if not line.startswith('+')]\n",
    "        \n",
    "        data_clean = []\n",
    "        for line in data_lines:\n",
    "            line_strip = line.strip()\n",
    "            if not line_strip:\n",
    "                continue\n",
    "            parts = [x.strip() for x in line_strip.strip('|').split('|')]\n",
    "            data_clean.append(parts)\n",
    "        \n",
    "        header = data_clean[0]\n",
    "        rows = data_clean[1:]\n",
    "        df_temp = pd.DataFrame(rows, columns=header)\n",
    "        \n",
    "        # Check columns\n",
    "        needed_cols = {'year', 'period', 'value'}\n",
    "        if not needed_cols.issubset(df_temp.columns):\n",
    "            print(f\"ERROR: Missing columns in {filepath}. Found: {df_temp.columns.tolist()}\")\n",
    "            continue\n",
    "        \n",
    "        # Convert columns\n",
    "        df_temp['year'] = df_temp['year'].astype(int)\n",
    "        df_temp['value'] = df_temp['value'].astype(float)\n",
    "        \n",
    "        # Extract month\n",
    "        df_temp['month'] = df_temp['period'].str.extract(r'M(\\d+)').astype(int)\n",
    "        \n",
    "        # Rename 'value' -> 'ppi'\n",
    "        df_temp.rename(columns={'value': 'ppi'}, inplace=True)\n",
    "        \n",
    "        # Keep only relevant columns\n",
    "        df_temp = df_temp[['year', 'month', 'ppi']]\n",
    "        \n",
    "        all_dfs.append(df_temp)\n",
    "    \n",
    "    \n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    combined_df.sort_values(by=['year', 'month'], inplace=True)\n",
    "    \n",
    "\n",
    "    combined_df['ppi_pro_change'] = combined_df['ppi'].pct_change()\n",
    "    \n",
    "    # Now we expand monthly data to daily\n",
    "    daily_rows = []\n",
    "    for _, row in combined_df.iterrows():\n",
    "        year = int(row['year'])\n",
    "        month = int(row['month'])\n",
    "        days_in_month = calendar.monthrange(year, month)[1]\n",
    "        start_date = datetime(year, month, 1)\n",
    "        \n",
    "        date_range = pd.date_range(start=start_date, periods=days_in_month)\n",
    "        for single_day in date_range:\n",
    "            daily_rows.append({\n",
    "                'date': single_day,\n",
    "                'ppi': row['ppi'],\n",
    "                'ppi_pro_change': row['ppi_pro_change']\n",
    "            })\n",
    "    \n",
    "    daily_df = pd.DataFrame(daily_rows)\n",
    "    \n",
    "    # Extract NACIS code from the *first* file in filepaths\n",
    "    basename = os.path.basename(filepaths[0])\n",
    "    match = re.search(r'PCU(\\d+)', basename)\n",
    "    nacis = match.group(1) if match else \"unknown\"\n",
    "        \n",
    "    out_dir = \"../data/processed\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_filename = f\"PPI{nacis}(03-25).csv\"\n",
    "    out_path = os.path.join(out_dir, out_filename)\n",
    "    \n",
    "    daily_df.to_csv(out_path, index=False)\n",
    "\n",
    "    \n",
    "    return daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Preview of combined daily DataFrame (first 10 rows) ===\n",
      "        date    ppi  ppi_pro_change\n",
      "0 2003-12-01  100.0             NaN\n",
      "1 2003-12-02  100.0             NaN\n",
      "2 2003-12-03  100.0             NaN\n",
      "3 2003-12-04  100.0             NaN\n",
      "4 2003-12-05  100.0             NaN\n",
      "5 2003-12-06  100.0             NaN\n",
      "6 2003-12-07  100.0             NaN\n",
      "7 2003-12-08  100.0             NaN\n",
      "8 2003-12-09  100.0             NaN\n",
      "9 2003-12-10  100.0             NaN\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    files_in_chron_order = [\n",
    "        \"../data/raw/ppi_and_cpi/PCU314---314---(03-12).txt\",\n",
    "        \"../data/raw/ppi_and_cpi/PCU314---314---(12-20).txt\",\n",
    "        \"../data/raw/ppi_and_cpi/PCU314---314---(20-25).txt\"\n",
    "    ]\n",
    "    # Process and combine them\n",
    "    result_df = process_ppi_files(files_in_chron_order)\n",
    "    if result_df is not None:\n",
    "        print(\"\\n=== Preview of combined daily DataFrame (first 10 rows) ===\")\n",
    "        print(result_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
